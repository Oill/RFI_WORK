{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HH1333134985_pksj1939-6342.1822.ms_all_data_baseline1and6.csv', 'HH1333305511_pksj1939-6342.1822.ms_all_data_baseline0and2.csv', 'HH1333305511_pksj1939-6342.1822.ms_all_data_baseline3and6.csv', 'HH1333305511_pks1613-586.1822.ms_all_data_baseline1and4.csv', 'HH1333305511_pksj1939-6342.1822.ms_all_data_baseline0and6.csv', 'HH1333305511_pks1613-586.1822.ms_all_data_baseline2and6.csv', 'HH1333305511_pks1613-586.1822.ms_all_data_baseline1and3.csv', 'HH1333305511_pks1613-586.1822.ms_all_data_baseline4and6.csv', 'HH1333134985_pks1613-586.1822.ms_all_data_baseline1and3.csv', 'HH1333305511_pks1613-586.1822.ms_all_data_baseline0and6.csv', 'HH1333134985_pks1613-586.1822.ms_all_data_baseline5and6.csv', 'HH1333305511_pks1613-586.1822.ms_all_data_baseline1and5.csv', 'HH1333305511_pksj1939-6342.1822.ms_all_data_baseline2and5.csv', 'HH1333134985_pks1613-586.1822.ms_all_data_baseline0and2.csv', 'HH1333305511_pksj1939-6342.1822.ms_all_data_baseline2and3.csv', 'HH1333134985_pksj1939-6342.1822.ms_all_data_baseline3and4.csv', 'HH1333134985_pksj1939-6342.1822.ms_all_data_baseline0and5.csv', 'HH1333305511_pks1613-586.1822.ms_all_data_baseline0and4.csv', 'HH1333305511_pksj1939-6342.1822.ms_all_data_baseline1and6.csv', 'HH1333305511_pksj1939-6342.1822.ms_all_data_baseline0and5.csv', 'HH1333134985_pksj1939-6342.1822.ms_all_data_baseline2and5.csv', 'HH1333134985_pks1613-586.1822.ms_all_data_baseline1and6.csv', 'HH1333134985_pks1613-586.1822.ms_all_data_baseline0and1.csv', 'HH1333305511_pks1613-586.1822.ms_all_data_baseline0and5.csv', 'HH1333305511_pks1613-586.1822.ms_all_data_baseline5and6.csv', 'HH1333305511_pks1613-586.1822.ms_all_data_baseline1and6.csv', 'HH1333305511_pksj1939-6342.1822.ms_all_data_baseline3and5.csv', 'HH1333134985_pks1613-586.1822.ms_all_data_baseline2and4.csv', 'HH1333134985_pks1613-586.1822.ms_all_data_baseline1and5.csv', 'HH1333134985_pks1613-586.1822.ms_all_data_baseline3and5.csv', 'HH1333134985_pksj1939-6342.1822.ms_all_data_baseline0and4.csv', 'HH1333134985_pks1613-586.1822.ms_all_data_baseline0and5.csv', 'HH1333134985_pks1613-586.1822.ms_all_data_baseline3and4.csv', 'HH1333134985_pks1613-586.1822.ms_all_data_baseline1and4.csv', 'HH1333305511_pksj1939-6342.1822.ms_all_data_baseline1and3.csv', 'HH1333134985_pksj1939-6342.1822.ms_all_data_baseline3and5.csv', 'HH1333305511_pks1613-586.1822.ms_all_data_baseline4and5.csv', 'HH1333134985_pks1613-586.1822.ms_all_data_baseline2and6.csv', 'HH1333305511_pks1613-586.1822.ms_all_data_baseline3and6.csv', 'HH1333134985_pks1613-586.1822.ms_all_data_baseline2and3.csv', 'HH1333134985_pksj1939-6342.1822.ms_all_data_baseline4and6.csv', 'HH1333134985_pksj1939-6342.1822.ms_all_data_baseline0and6.csv', 'HH1333134985_pksj1939-6342.1822.ms_all_data_baseline2and6.csv', 'HH1333305511_pksj1939-6342.1822.ms_all_data_baseline4and6.csv', 'HH1333134985_pks1613-586.1822.ms_all_data_baseline0and4.csv', 'HH1333134985_pksj1939-6342.1822.ms_all_data_baseline5and6.csv', 'HH1333305511_pksj1939-6342.1822.ms_all_data_baseline1and2.csv', 'HH1333305511_pks1613-586.1822.ms_all_data_baseline0and3.csv', 'HH1333134985_pksj1939-6342.1822.ms_all_data_baseline2and4.csv', 'HH1333305511_pks1613-586.1822.ms_all_data_baseline1and2.csv', 'HH1333305511_pksj1939-6342.1822.ms_all_data_baseline0and4.csv', 'HH1333134985_pksj1939-6342.1822.ms_all_data_baseline0and3.csv', 'HH1333305511_pksj1939-6342.1822.ms_all_data_baseline2and4.csv', 'HH1333134985_pksj1939-6342.1822.ms_all_data_baseline1and4.csv', 'HH1333305511_pksj1939-6342.1822.ms_all_data_baseline1and4.csv', 'HH1333134985_pksj1939-6342.1822.ms_all_data_baseline3and6.csv', 'HH1333305511_pks1613-586.1822.ms_all_data_baseline0and1.csv', 'HH1333134985_pksj1939-6342.1822.ms_all_data_baseline0and2.csv', 'HH1333134985_pks1613-586.1822.ms_all_data_baseline3and6.csv', 'HH1333305511_pksj1939-6342.1822.ms_all_data_baseline0and3.csv', 'HH1333134985_pks1613-586.1822.ms_all_data_baseline0and3.csv', 'HH1333134985_pksj1939-6342.1822.ms_all_data_baseline2and3.csv', 'HH1333134985_pks1613-586.1822.ms_all_data_baseline1and2.csv', 'HH1333134985_pksj1939-6342.1822.ms_all_data_baseline4and5.csv', 'HH1333134985_pks1613-586.1822.ms_all_data_baseline4and6.csv', 'HH1333305511_pks1613-586.1822.ms_all_data_baseline2and5.csv', 'HH1333305511_pks1613-586.1822.ms_all_data_baseline2and4.csv', 'HH1333305511_pks1613-586.1822.ms_all_data_baseline2and3.csv', 'HH1333134985_pksj1939-6342.1822.ms_all_data_baseline1and5.csv', 'HH1333134985_pksj1939-6342.1822.ms_all_data_baseline1and3.csv', 'HH1333305511_pks1613-586.1822.ms_all_data_baseline3and5.csv', 'HH1333134985_pks1613-586.1822.ms_all_data_baseline2and5.csv', 'HH1333134985_pks1613-586.1822.ms_all_data_baseline0and6.csv', 'HH1333305511_pks1613-586.1822.ms_all_data_baseline3and4.csv', 'HH1333305511_pksj1939-6342.1822.ms_all_data_baseline1and5.csv', 'HH1333305511_pksj1939-6342.1822.ms_all_data_baseline2and6.csv', 'HH1333134985_pksj1939-6342.1822.ms_all_data_baseline1and2.csv', 'HH1333305511_pksj1939-6342.1822.ms_all_data_baseline4and5.csv', 'HH1333305511_pksj1939-6342.1822.ms_all_data_baseline3and4.csv', 'HH1333305511_pks1613-586.1822.ms_all_data_baseline0and2.csv', 'HH1333305511_pksj1939-6342.1822.ms_all_data_baseline0and1.csv', 'HH1333305511_pksj1939-6342.1822.ms_all_data_baseline5and6.csv', 'HH1333134985_pksj1939-6342.1822.ms_all_data_baseline0and1.csv', 'HH1333134985_pks1613-586.1822.ms_all_data_baseline4and5.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "# Some preprocessing utilities\n",
    "from sklearn.cross_validation import train_test_split # Data splitting\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "# Model result function\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "import itertools\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import normalize\n",
    "sns.set_context('paper')\n",
    "palette = sns.plt.cm.gray_r\n",
    "# set masked values to plot red\n",
    "palette.set_bad('r', 1.0)\n",
    "%matplotlib inline\n",
    "\n",
    "data_files = glob.glob(\"HH133*\")#+ glob.glob(\"HH13*pks16*0and2*csv\")\n",
    "print data_files\n",
    "\n",
    "names = [\"d_p\",\"tC_mean\",\"tp_mean\",'t_skew','t_kurtosis','t_cumsumx','t_sumvalues'\n",
    "         ,'t_slope','t_per25','t_per75','t_var',\"fC_mean\",\"fp_mean\",'f_skew'\n",
    "         ,'f_kurtosis','f_cumsumx','f_sumvalues','f_slope','f_per25','f_per75','f_var']\n",
    "target_names = ['Not RFI','RFI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/data/olorato/mywork/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "datasets = []\n",
    "files = []\n",
    "for filename in data_files:#[:15]:\n",
    "    data = pd.DataFrame.from_csv(filename)\n",
    "    if True:#len(np.where(data[\"rfi\"].values == 1)[0])/float(len(data[\"rfi\"])) < 0.4:\n",
    "        try:\n",
    "            for name in names:\n",
    "                data[name] = normalize(data[name],norm='l2')[0]\n",
    "            HH_X0 = data\n",
    "            files.append(filename)\n",
    "            del data\n",
    "            data = pd.DataFrame.from_csv(filename.replace('HH','VV'))\n",
    "            for name in names:\n",
    "                data[name] = normalize(data[name],norm='l2')[0]\n",
    "            VV_X0 = data\n",
    "            del data\n",
    "            data = pd.DataFrame.from_csv(filename.replace('HH','HV'))\n",
    "            for name in names:\n",
    "                data[name] = normalize(data[name],norm='l2')[0]\n",
    "            HV_X0 = data\n",
    "            del data\n",
    "\n",
    "\n",
    "            x_train0HH, x_test0HH, y_train0HH, y_test0HH = train_test_split(HH_X0[names], HH_X0['rfi'], test_size=0.30,random_state=0)\n",
    "\n",
    "            x_train0HV, x_test0HV, y_train0HV, y_test0HV = train_test_split(HV_X0[names], HV_X0['rfi'], test_size=0.30,random_state=0)\n",
    "\n",
    "            x_train0VV, x_test0VV, y_train0VV, y_test0VV = train_test_split(VV_X0[names], VV_X0['rfi'], test_size=0.30,random_state=0)\n",
    "\n",
    "            x_train0HH['rfi'] = y_train0HH\n",
    "            x_train0VV['rfi'] = y_train0VV\n",
    "            x_train0HV['rfi'] = y_train0HV\n",
    "\n",
    "            HHrfc = GaussianNB()\n",
    "            HHrfc.fit(x_train0HH[names],y_train0HH)\n",
    "            HHy_pred_prob_rfc = HHrfc.predict_proba(x_test0HH)\n",
    "            HHy_pred_rfc = HHrfc.predict(x_test0HH)\n",
    "\n",
    "            VVrfc = GaussianNB()\n",
    "            VVrfc.fit(x_train0VV[names],y_train0VV)\n",
    "            VVy_pred_prob_rfc = VVrfc.predict_proba(x_test0VV)\n",
    "            VVy_pred_rfc = VVrfc.predict(x_test0VV)\n",
    "\n",
    "            HVrfc = GaussianNB()\n",
    "            HVrfc.fit(x_train0HV[names],y_train0HV)\n",
    "            HVy_pred_prob_rfc = HVrfc.predict_proba(x_test0HV)\n",
    "            HVy_pred_rfc = HVrfc.predict(x_test0HV)\n",
    "\n",
    "            def roc_plot(classifiers,subplot,model_names):\n",
    "        #c = ['r','g','b']\n",
    "                if subplot == True:\n",
    "                    num = len(classifiers)\n",
    "                    sns.plt.figure()\n",
    "                    for i in range(num):\n",
    "                        sns.plt.subplot(1,num,i+1)\n",
    "                        clf = classifiers[i]\n",
    "                        y_roc_fpr, y_roc_tpr, y_roc_thresholds = roc_curve(y_test0, clf[:,1])\n",
    "                        sns.plt.plot(y_roc_fpr, y_roc_tpr,label=model_names[i]+' AUC = %0.2f'% auc(y_roc_fpr, y_roc_tpr))\n",
    "                        sns.plt.legend(loc='lower right',fontsize = 20 )\n",
    "                        sns.plt.plot([0,1],[0,1],'r--')\n",
    "                        sns.plt.xlim([-0.1,1.2])\n",
    "                        sns.plt.ylim([-0.1,1.2])\n",
    "                        sns.plt.ylabel('True Positive Rate',fontsize = 34 ,fontweight='bold')\n",
    "                        sns.plt.xlabel('False Positive Rate',fontsize = 34 ,fontweight='bold')\n",
    "                        sns.plt.xticks(size=18)\n",
    "                        sns.plt.yticks(size=18)\n",
    "                if subplot == False:\n",
    "                    num = len(classifiers)\n",
    "                    sns.plt.figure(figsize=(20,20))\n",
    "                    for i in range(num):\n",
    "                        clf = classifiers[i]\n",
    "                        if 'VV' in model_names[i]:\n",
    "                            y_roc_fpr, y_roc_tpr, y_roc_thresholds = roc_curve(y_test0VV, clf[:,1])\n",
    "                        elif 'HV' in model_names[i]:\n",
    "                            y_roc_fpr, y_roc_tpr, y_roc_thresholds = roc_curve(y_test0HV, clf[:,1])\n",
    "                        else:\n",
    "                            y_roc_fpr, y_roc_tpr, y_roc_thresholds = roc_curve(y_test0HH, clf[:,1])\n",
    "                        sns.plt.plot(y_roc_fpr, y_roc_tpr,label=model_names[i]+' AUC = %0.2f'% auc(y_roc_fpr, y_roc_tpr))\n",
    "                        sns.plt.legend(loc='lower right',fontsize = 20 )\n",
    "                        sns.plt.plot([0,1],[0,1],'r--')\n",
    "                        sns.plt.xlim([-0.1,1.2])\n",
    "                        sns.plt.ylim([-0.1,1.2])\n",
    "                        sns.plt.ylabel('True Positive Rate',fontsize = 34 ,fontweight='bold')\n",
    "                        sns.plt.xlabel('False Positive Rate',fontsize = 34 ,fontweight='bold')\n",
    "                        sns.plt.xticks(size=18)\n",
    "                        sns.plt.yticks(size=18)\n",
    "                sns.plt.savefig('ROC_Same_source_'+filename.split(\"_\")[1].split('.')[0]+'_and_baseline_'+filename.split('baseline')[-1].split('.')[0]+'_cross_validation_NB.eps', format='eps', dpi=600)\n",
    "                return\n",
    "            model_names =['HH','VV','HV']\n",
    "            roc_plot([HHy_pred_prob_rfc ,VVy_pred_prob_rfc,HVy_pred_prob_rfc],False,model_names)\n",
    "\n",
    "            cnf_matrix = confusion_matrix(y_test0HH,HHy_pred_rfc)\n",
    "            sns.plt.figure(figsize=(20,20))\n",
    "            sns.plt.imshow(cnf_matrix, interpolation='nearest', cmap=sns.plt.cm.Blues)\n",
    "            classes = target_names \n",
    "            #sns.plt.title(title)\n",
    "            sns.plt.colorbar()\n",
    "            tick_marks = np.arange(len(classes))\n",
    "            sns.plt.xticks(tick_marks, classes, rotation=45)\n",
    "            sns.plt.yticks(tick_marks, classes)\n",
    "\n",
    "            #if normalize:\n",
    "            #    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "                #print(\"Normalized confusion matrix\")\n",
    "            #else:\n",
    "            #    pass\n",
    "                #print('Confusion matrix, without normalization')\n",
    "\n",
    "            #print(cm)\n",
    "\n",
    "            thresh = cnf_matrix.max() / 2.\n",
    "            for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n",
    "                sns.plt.text(j, i, round(cnf_matrix[i, j],3),\n",
    "                         horizontalalignment=\"center\",\n",
    "                         color=\"white\" if cnf_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "            sns.plt.tight_layout()\n",
    "            sns.plt.grid(False)\n",
    "            sns.plt.ylabel('True label',fontsize = 34 ,fontweight='bold')\n",
    "            sns.plt.xlabel('Predicted label',fontsize = 34 ,fontweight='bold')\n",
    "            sns.plt.xticks(size=18)\n",
    "            sns.plt.yticks(size=18)\n",
    "            sns.plt.savefig('HH_Confusion_matrix_Same_source_'+filename.split(\"_\")[1].split('.')[0]+'_and_baseline_'+filename.split('baseline')[-1].split('.')[0]+'_cross_validation_NB.eps', format='eps', dpi=600)\n",
    "\n",
    "            open_file = open('HH_class_Same_source_'+filename.split(\"_\")[1].split('.')[0]+'_and_baseline_'+filename.split('baseline')[-1].split('.')[0]+'_cross_validation_NB.txt','w')\n",
    "\n",
    "            open_file.write('====================================================')\n",
    "            open_file.write('Classification Report for HH')\n",
    "            open_file.write('====================================================')\n",
    "            open_file.write(classification_report(y_test0HH,HHy_pred_rfc,target_names=['Not RFI','RFI']))\n",
    "            open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0HH,HHy_pred_rfc)*100))\n",
    "            open_file.close()\n",
    "\n",
    "            cnf_matrix = confusion_matrix(y_test0HV,HVy_pred_rfc)\n",
    "            sns.plt.figure(figsize=(20,20))\n",
    "            sns.plt.imshow(cnf_matrix, interpolation='nearest', cmap=sns.plt.cm.Blues)\n",
    "            classes = target_names \n",
    "            #sns.plt.title(title)\n",
    "            sns.plt.colorbar()\n",
    "            tick_marks = np.arange(len(classes))\n",
    "            sns.plt.xticks(tick_marks, classes, rotation=45)\n",
    "            sns.plt.yticks(tick_marks, classes)\n",
    "\n",
    "            #if normalize:\n",
    "            #    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "                #print(\"Normalized confusion matrix\")\n",
    "            #else:\n",
    "            #    pass\n",
    "                #print('Confusion matrix, without normalization')\n",
    "\n",
    "            #print(cm)\n",
    "\n",
    "            thresh = cnf_matrix.max() / 2.\n",
    "            for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n",
    "                sns.plt.text(j, i, round(cnf_matrix[i, j],3),\n",
    "                         horizontalalignment=\"center\",\n",
    "                         color=\"white\" if cnf_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "            sns.plt.tight_layout()\n",
    "            sns.plt.grid(False)\n",
    "            sns.plt.ylabel('True label',fontsize = 34 ,fontweight='bold')\n",
    "            sns.plt.xlabel('Predicted label',fontsize = 34 ,fontweight='bold')\n",
    "            sns.plt.xticks(size=18)\n",
    "            sns.plt.yticks(size=18)\n",
    "            sns.plt.savefig('HV_Confusion_matrix_Same_source_'+filename.split(\"_\")[1].split('.')[0]+'_and_baseline_'+filename.split('baseline')[-1].split('.')[0]+'_cross_validation_NB.eps', format='eps', dpi=600)\n",
    "\n",
    "            open_file = open('HV_class_Same_source_'+filename.split(\"_\")[1].split('.')[0]+'_and_baseline_'+filename.split('baseline')[-1].split('.')[0]+'_cross_validation_NB.txt','w')\n",
    "\n",
    "            open_file.write('====================================================')\n",
    "            open_file.write('Classification Report for HV')\n",
    "            open_file.write('====================================================')\n",
    "            open_file.write(classification_report(y_test0HV,HVy_pred_rfc,target_names=['Not RFI','RFI']))\n",
    "            open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0HV,HVy_pred_rfc)*100))\n",
    "            open_file.close()\n",
    "\n",
    "            cnf_matrix = confusion_matrix(y_test0VV,VVy_pred_rfc)\n",
    "            sns.plt.figure(figsize=(20,20))\n",
    "            sns.plt.imshow(cnf_matrix, interpolation='nearest', cmap=sns.plt.cm.Blues)\n",
    "            classes = target_names \n",
    "            #sns.plt.title(title)\n",
    "            sns.plt.colorbar()\n",
    "            tick_marks = np.arange(len(classes))\n",
    "            sns.plt.xticks(tick_marks, classes, rotation=45)\n",
    "            sns.plt.yticks(tick_marks, classes)\n",
    "\n",
    "            #if normalize:\n",
    "            #    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "                #print(\"Normalized confusion matrix\")\n",
    "            #else:\n",
    "            #    pass\n",
    "                #print('Confusion matrix, without normalization')\n",
    "\n",
    "            #print(cm)\n",
    "\n",
    "            thresh = cnf_matrix.max() / 2.\n",
    "            for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n",
    "                sns.plt.text(j, i, round(cnf_matrix[i, j],3),\n",
    "                         horizontalalignment=\"center\",\n",
    "                         color=\"white\" if cnf_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "            sns.plt.tight_layout()\n",
    "            sns.plt.grid(False)\n",
    "            sns.plt.ylabel('True label',fontsize = 34 ,fontweight='bold')\n",
    "            sns.plt.xlabel('Predicted label',fontsize = 34 ,fontweight='bold')\n",
    "            sns.plt.xticks(size=18)\n",
    "            sns.plt.yticks(size=18)\n",
    "            sns.plt.savefig('VV_Confusion_matrix_Same_source_'+filename.split(\"_\")[1].split('.')[0]+'_and_baseline_'+filename.split('baseline')[-1].split('.')[0]+'_cross_validation_NB.eps', format='eps', dpi=600)\n",
    "\n",
    "            open_file = open('VV_class_Same_source_'+filename.split(\"_\")[1].split('.')[0]+'_and_baseline_'+filename.split('baseline')[-1].split('.')[0]+'_cross_validation_NB.txt','w')\n",
    "\n",
    "            open_file.write('====================================================')\n",
    "            open_file.write('Classification Report for VV')\n",
    "            open_file.write('====================================================')\n",
    "            open_file.write(classification_report(y_test0VV,VVy_pred_rfc,target_names=['Not RFI','RFI']))\n",
    "            open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0VV,VVy_pred_rfc)*100))\n",
    "            open_file.close()\n",
    "\n",
    "            #testVV = pd.DataFrame.from_csv('VV1333305511_pks1613-586.1822.ms_all_data_baseline0and1.csv')\n",
    "            open_file = open('poltest_Same_source_'+filename.split(\"_\")[1].split('.')[0]+'_and_baseline_'+filename.split('baseline')[-1].split('.')[0]+'_cross_validation_NB.txt','w')\n",
    "\n",
    "            open_file.write(\"HH\")\n",
    "            y_pred_rfc = HHrfc.predict(x_test0HH)\n",
    "            open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0HH,y_pred_rfc)*100))\n",
    "\n",
    "            y_pred_rfc = HHrfc.predict(x_test0VV)\n",
    "            open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0VV,y_pred_rfc)*100))\n",
    "\n",
    "            y_pred_rfc = HHrfc.predict(x_test0HV)\n",
    "            open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0HV,y_pred_rfc)*100))\n",
    "\n",
    "\n",
    "            open_file.write(\"VV\")\n",
    "            y_pred_rfc = VVrfc.predict(x_test0HH)\n",
    "            open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0HH,y_pred_rfc)*100))\n",
    "\n",
    "            y_pred_rfc = VVrfc.predict(x_test0VV)\n",
    "            open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0VV,y_pred_rfc)*100))\n",
    "\n",
    "            y_pred_rfc = VVrfc.predict(x_test0HV)\n",
    "            open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0HV,y_pred_rfc)*100))\n",
    "\n",
    "            open_file.write(\"HV\")\n",
    "            y_pred_rfc = HVrfc.predict(x_test0HH)\n",
    "            open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0HH,y_pred_rfc)*100))\n",
    "\n",
    "            y_pred_rfc = HVrfc.predict(x_test0VV)\n",
    "            open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0VV,y_pred_rfc)*100))\n",
    "\n",
    "            y_pred_rfc = HVrfc.predict(x_test0HV)\n",
    "            open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0HV,y_pred_rfc)*100))\n",
    "\n",
    "            open_file.close()\n",
    "\n",
    "\n",
    "            pickle.dump(HHrfc,open('HH_Same_source_'+filename.split(\"_\")[1].split('.')[0]+'_and_baseline_'+filename.split('baseline')[-1].split('.')[0]+'_cross_validation_NB.p','wb'))\n",
    "            pickle.dump(HVrfc,open('HV_Same_source_'+filename.split(\"_\")[1].split('.')[0]+'_and_baseline_'+filename.split('baseline')[-1].split('.')[0]+'_cross_validation_NB.p','wb'))\n",
    "            pickle.dump(VVrfc,open('VV_Same_source_'+filename.split(\"_\")[1].split('.')[0]+'_and_baseline_'+filename.split('baseline')[-1].split('.')[0]+'_cross_validation_NB.p','wb'))\n",
    "        except Exception as e:\n",
    "            print e\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasets = []\n",
    "files = []\n",
    "for filename in data_files:#[:15]:\n",
    "    data = pd.DataFrame.from_csv(filename)\n",
    "    if len(np.where(data[\"rfi\"].values == 1)[0])/float(len(data[\"rfi\"])) < 0.4:\n",
    "        for name in names:\n",
    "            data[name] = normalize(data[name],norm='l2')[0]\n",
    "        HH_X0 = data\n",
    "        files.append(filename)\n",
    "        del data\n",
    "        data = pd.DataFrame.from_csv(filename.replace('HH','VV'))\n",
    "        for name in names:\n",
    "            data[name] = normalize(data[name],norm='l2')[0]\n",
    "        VV_X0 = data\n",
    "        del data\n",
    "        data = pd.DataFrame.from_csv(filename.replace('HH','HV'))\n",
    "        for name in names:\n",
    "            data[name] = normalize(data[name],norm='l2')[0]\n",
    "        HV_X0 = data\n",
    "        del data\n",
    "        \n",
    "        \n",
    "        x_train0HH, x_test0HH, y_train0HH, y_test0HH = train_test_split(HH_X0[names], HH_X0['rfi'], test_size=0.30,random_state=0)\n",
    "\n",
    "        x_train0HV, x_test0HV, y_train0HV, y_test0HV = train_test_split(HV_X0[names], HV_X0['rfi'], test_size=0.30,random_state=0)\n",
    "\n",
    "        x_train0VV, x_test0VV, y_train0VV, y_test0VV = train_test_split(VV_X0[names], VV_X0['rfi'], test_size=0.30,random_state=0)\n",
    "\n",
    "        x_train0HH['rfi'] = y_train0HH\n",
    "        x_train0VV['rfi'] = y_train0VV\n",
    "        x_train0HV['rfi'] = y_train0HV\n",
    "        \n",
    "        \n",
    "        HHcv = StratifiedKFold(x_train0HH, n_folds=15,shuffle=True, random_state=0)\n",
    "        VVcv = StratifiedKFold(x_train0VV, n_folds=15,shuffle=True, random_state=0)\n",
    "        HVcv = StratifiedKFold(x_train0HV, n_folds=15,shuffle=True, random_state=0)\n",
    "        rfc = RandomForestClassifier(random_state=0)\n",
    "        grid = {'n_estimators': np.arange(1, 11)\n",
    "                ,'criterion': ['gini', 'entropy']\n",
    "                ,'max_features':['sqrt','log2']\n",
    "                ,'max_depth':np.arange(2,11)\n",
    "                ,\"min_samples_split\": np.arange(2, 11)\n",
    "                ,\"min_samples_leaf\": np.arange(2, 11)\n",
    "                ,\"bootstrap\": [True, False]\n",
    "                ,'min_samples_split':np.arange(2,11)}\n",
    "\n",
    "        HHrfc = RandomizedSearchCV(rfc, grid, cv=HHcv,n_iter=20)\n",
    "        HHrfc.fit(x_train0HH[names],y_train0HH)\n",
    "        VVrfc = RandomizedSearchCV(rfc, grid, cv=VVcv,n_iter=20)\n",
    "        VVrfc.fit(x_train0VV[names],y_train0VV)\n",
    "        HVrfc = RandomizedSearchCV(rfc, grid, cv=HVcv,n_iter=20)\n",
    "        HVrfc.fit(x_train0HV[names],y_train0HV)\n",
    "        \n",
    "        \n",
    "        HHrfc = HHrfc.best_estimator_\n",
    "        HHrfc.fit(x_train0HH[names],y_train0HH)\n",
    "        HHy_pred_prob_rfc = HHrfc.predict_proba(x_test0HH)\n",
    "        HHy_pred_rfc = HHrfc.predict(x_test0HH)\n",
    "        \n",
    "        VVrfc = VVrfc.best_estimator_\n",
    "        VVrfc.fit(x_train0VV[names],y_train0VV)\n",
    "        VVy_pred_prob_rfc = VVrfc.predict_proba(x_test0VV)\n",
    "        VVy_pred_rfc = VVrfc.predict(x_test0VV)\n",
    "\n",
    "        HVrfc = HHrfc.best_estimator_\n",
    "        HVrfc.fit(x_train0HV[names],y_train0HV)\n",
    "        HVy_pred_prob_rfc = HVrfc.predict_proba(x_test0HV)\n",
    "        HVy_pred_rfc = HVrfc.predict(x_test0HV)\n",
    "        \n",
    "        def roc_plot(classifiers,subplot,model_names):\n",
    "    #c = ['r','g','b']\n",
    "            if subplot == True:\n",
    "                num = len(classifiers)\n",
    "                sns.plt.figure()\n",
    "                for i in range(num):\n",
    "                    sns.plt.subplot(1,num,i+1)\n",
    "                    clf = classifiers[i]\n",
    "                    y_roc_fpr, y_roc_tpr, y_roc_thresholds = roc_curve(y_test0, clf[:,1])\n",
    "                    sns.plt.plot(y_roc_fpr, y_roc_tpr,label=model_names[i]+' AUC = %0.2f'% auc(y_roc_fpr, y_roc_tpr))\n",
    "                    sns.plt.legend(loc='lower right',fontsize = 20 )\n",
    "                    sns.plt.plot([0,1],[0,1],'r--')\n",
    "                    sns.plt.xlim([-0.1,1.2])\n",
    "                    sns.plt.ylim([-0.1,1.2])\n",
    "                    sns.plt.ylabel('True Positive Rate',fontsize = 34 ,fontweight='bold')\n",
    "                    sns.plt.xlabel('False Positive Rate',fontsize = 34 ,fontweight='bold')\n",
    "                    sns.plt.xticks(size=18)\n",
    "                    sns.plt.yticks(size=18)\n",
    "            if subplot == False:\n",
    "                num = len(classifiers)\n",
    "                sns.plt.figure(figsize=(10,10))\n",
    "                for i in range(num):\n",
    "                    clf = classifiers[i]\n",
    "                    if 'VV' in model_names[i]:\n",
    "                        y_roc_fpr, y_roc_tpr, y_roc_thresholds = roc_curve(y_test0VV, clf[:,1])\n",
    "                    elif 'HV' in model_names[i]:\n",
    "                        y_roc_fpr, y_roc_tpr, y_roc_thresholds = roc_curve(y_test0HV, clf[:,1])\n",
    "                    else:\n",
    "                        y_roc_fpr, y_roc_tpr, y_roc_thresholds = roc_curve(y_test0HH, clf[:,1])\n",
    "                    sns.plt.plot(y_roc_fpr, y_roc_tpr,label=model_names[i]+' AUC = %0.2f'% auc(y_roc_fpr, y_roc_tpr))\n",
    "                    sns.plt.legend(loc='lower right',fontsize = 20 )\n",
    "                    sns.plt.plot([0,1],[0,1],'r--')\n",
    "                    sns.plt.xlim([-0.1,1.2])\n",
    "                    sns.plt.ylim([-0.1,1.2])\n",
    "                    sns.plt.ylabel('True Positive Rate',fontsize = 34 ,fontweight='bold')\n",
    "                    sns.plt.xlabel('False Positive Rate',fontsize = 34 ,fontweight='bold')\n",
    "                    sns.plt.xticks(size=18)\n",
    "                    sns.plt.yticks(size=18)\n",
    "            sns.plt.savefig('ROC_Same_source_'+filename.split(\"_\")[1].split('.')[0]+'_and_baseline_'+filename.split('baseline')[-1].split('.')[0]+'_cross_validation_RFC.eps', format='eps', dpi=600)\n",
    "            return\n",
    "        model_names =['HH','VV','HV']\n",
    "        roc_plot([HHy_pred_prob_rfc ,VVy_pred_prob_rfc,HVy_pred_prob_rfc],False,model_names)\n",
    "        \n",
    "        cnf_matrix = confusion_matrix(y_test0HH,HHy_pred_rfc)\n",
    "        sns.plt.figure(figsize=(20,20))\n",
    "        sns.plt.imshow(cnf_matrix, interpolation='nearest', cmap=sns.plt.cm.Blues)\n",
    "        classes = target_names \n",
    "        #sns.plt.title(title)\n",
    "        sns.plt.colorbar()\n",
    "        tick_marks = np.arange(len(classes))\n",
    "        sns.plt.xticks(tick_marks, classes, rotation=45)\n",
    "        sns.plt.yticks(tick_marks, classes)\n",
    "\n",
    "        #if normalize:\n",
    "        #    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            #print(\"Normalized confusion matrix\")\n",
    "        #else:\n",
    "        #    pass\n",
    "            #print('Confusion matrix, without normalization')\n",
    "\n",
    "        #print(cm)\n",
    "\n",
    "        thresh = cnf_matrix.max() / 2.\n",
    "        for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n",
    "            sns.plt.text(j, i, round(cnf_matrix[i, j],3),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cnf_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "        sns.plt.tight_layout()\n",
    "        sns.plt.grid(False)\n",
    "        sns.plt.ylabel('True label',fontsize = 34 ,fontweight='bold')\n",
    "        sns.plt.xlabel('Predicted label',fontsize = 34 ,fontweight='bold')\n",
    "        sns.plt.xticks(size=18)\n",
    "        sns.plt.yticks(size=18)\n",
    "        sns.plt.savefig('HH_Confusion_matrix_Same_source_'+filename.split(\"_\")[1].split('.')[0]+'_and_baseline_'+filename.split('baseline')[-1].split('.')[0]+'_cross_validation_RFC.eps', format='eps', dpi=600)\n",
    "        \n",
    "        open_file = open('HH_class_Same_source_'+filename.split(\"_\")[1].split('.')[0]+'_and_baseline_'+filename.split('baseline')[-1].split('.')[0]+'_cross_validation_RFC.txt','w')\n",
    "        \n",
    "        open_file.write('====================================================')\n",
    "        open_file.write('Classification Report for HH')\n",
    "        open_file.write('====================================================')\n",
    "        open_file.write(classification_report(y_test0HH,HHy_pred_rfc,target_names=['Not RFI','RFI']))\n",
    "        open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0HH,HHy_pred_rfc)*100))\n",
    "        open_file.close()\n",
    "        \n",
    "        cnf_matrix = confusion_matrix(y_test0HV,HVy_pred_rfc)\n",
    "        sns.plt.figure(figsize=(20,20))\n",
    "        sns.plt.imshow(cnf_matrix, interpolation='nearest', cmap=sns.plt.cm.Blues)\n",
    "        classes = target_names \n",
    "        #sns.plt.title(title)\n",
    "        sns.plt.colorbar()\n",
    "        tick_marks = np.arange(len(classes))\n",
    "        sns.plt.xticks(tick_marks, classes, rotation=45)\n",
    "        sns.plt.yticks(tick_marks, classes)\n",
    "\n",
    "        #if normalize:\n",
    "        #    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            #print(\"Normalized confusion matrix\")\n",
    "        #else:\n",
    "        #    pass\n",
    "            #print('Confusion matrix, without normalization')\n",
    "\n",
    "        #print(cm)\n",
    "\n",
    "        thresh = cnf_matrix.max() / 2.\n",
    "        for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n",
    "            sns.plt.text(j, i, round(cnf_matrix[i, j],3),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cnf_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "        sns.plt.tight_layout()\n",
    "        sns.plt.grid(False)\n",
    "        sns.plt.ylabel('True label',fontsize = 34 ,fontweight='bold')\n",
    "        sns.plt.xlabel('Predicted label',fontsize = 34 ,fontweight='bold')\n",
    "        sns.plt.xticks(size=18)\n",
    "        sns.plt.yticks(size=18)\n",
    "        sns.plt.savefig('HV_Confusion_matrix_Same_source_'+filename.split(\"_\")[1].split('.')[0]+'_and_baseline_'+filename.split('baseline')[-1].split('.')[0]+'_cross_validation_RFC.eps', format='eps', dpi=600)\n",
    "        \n",
    "        open_file = open('HV_class_Same_source_'+filename.split(\"_\")[1].split('.')[0]+'_and_baseline_'+filename.split('baseline')[-1].split('.')[0]+'_cross_validation_RFC.txt','w')\n",
    "        \n",
    "        open_file.write('====================================================')\n",
    "        open_file.write('Classification Report for HV')\n",
    "        open_file.write('====================================================')\n",
    "        open_file.write(classification_report(y_test0HV,HVy_pred_rfc,target_names=['Not RFI','RFI']))\n",
    "        open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0HV,HVy_pred_rfc)*100))\n",
    "        open_file.close()\n",
    "        \n",
    "        cnf_matrix = confusion_matrix(y_test0VV,VVy_pred_rfc)\n",
    "        sns.plt.figure(figsize=(20,20))\n",
    "        sns.plt.imshow(cnf_matrix, interpolation='nearest', cmap=sns.plt.cm.Blues)\n",
    "        classes = target_names \n",
    "        #sns.plt.title(title)\n",
    "        sns.plt.colorbar()\n",
    "        tick_marks = np.arange(len(classes))\n",
    "        sns.plt.xticks(tick_marks, classes, rotation=45)\n",
    "        sns.plt.yticks(tick_marks, classes)\n",
    "\n",
    "        #if normalize:\n",
    "        #    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            #print(\"Normalized confusion matrix\")\n",
    "        #else:\n",
    "        #    pass\n",
    "            #print('Confusion matrix, without normalization')\n",
    "\n",
    "        #print(cm)\n",
    "\n",
    "        thresh = cnf_matrix.max() / 2.\n",
    "        for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n",
    "            sns.plt.text(j, i, round(cnf_matrix[i, j],3),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cnf_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "        sns.plt.tight_layout()\n",
    "        sns.plt.grid(False)\n",
    "        sns.plt.ylabel('True label',fontsize = 34 ,fontweight='bold')\n",
    "        sns.plt.xlabel('Predicted label',fontsize = 34 ,fontweight='bold')\n",
    "        sns.plt.xticks(size=18)\n",
    "        sns.plt.yticks(size=18)\n",
    "        sns.plt.savefig('VV_Confusion_matrix_Same_source_'+filename.split(\"_\")[1].split('.')[0]+'_and_baseline_'+filename.split('baseline')[-1].split('.')[0]+'_cross_validation_RFC.eps', format='eps', dpi=600)\n",
    "        \n",
    "        open_file = open('VV_class_Same_source_'+filename.split(\"_\")[1].split('.')[0]+'_and_baseline_'+filename.split('baseline')[-1].split('.')[0]+'_cross_validation_RFC.txt','w')\n",
    "        \n",
    "        open_file.write('====================================================')\n",
    "        open_file.write('Classification Report for VV')\n",
    "        open_file.write('====================================================')\n",
    "        open_file.write(classification_report(y_test0VV,VVy_pred_rfc,target_names=['Not RFI','RFI']))\n",
    "        open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0VV,VVy_pred_rfc)*100))\n",
    "        open_file.close()\n",
    "        \n",
    "        #testVV = pd.DataFrame.from_csv('VV1333305511_pks1613-586.1822.ms_all_data_baseline0and1.csv')\n",
    "        open_file = open('poltest_Same_source_'+filename.split(\"_\")[1].split('.')[0]+'_and_baseline_'+filename.split('baseline')[-1].split('.')[0]+'_cross_validation_RFC.txt','w')\n",
    "\n",
    "        open_file.write(\"HH\")\n",
    "        y_pred_rfc = HHrfc.predict(x_test0HH)\n",
    "        open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0HH,y_pred_rfc)*100))\n",
    "\n",
    "        y_pred_rfc = HHrfc.predict(x_test0VV)\n",
    "        open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0VV,y_pred_rfc)*100))\n",
    "\n",
    "        y_pred_rfc = HHrfc.predict(x_test0HV)\n",
    "        open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0HV,y_pred_rfc)*100))\n",
    "\n",
    "\n",
    "        open_file.write(\"VV\")\n",
    "        y_pred_rfc = VVrfc.predict(x_test0HH)\n",
    "        open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0HH,y_pred_rfc)*100))\n",
    "\n",
    "        y_pred_rfc = VVrfc.predict(x_test0VV)\n",
    "        open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0VV,y_pred_rfc)*100))\n",
    "\n",
    "        y_pred_rfc = VVrfc.predict(x_test0HV)\n",
    "        open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0HV,y_pred_rfc)*100))\n",
    "\n",
    "        open_file.write(\"HV\")\n",
    "        y_pred_rfc = HVrfc.predict(x_test0HH)\n",
    "        open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0HH,y_pred_rfc)*100))\n",
    "\n",
    "        y_pred_rfc = HVrfc.predict(x_test0VV)\n",
    "        open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0VV,y_pred_rfc)*100))\n",
    "\n",
    "        y_pred_rfc = HVrfc.predict(x_test0HV)\n",
    "        open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0HV,y_pred_rfc)*100))\n",
    "        \n",
    "        open_file.close()\n",
    "\n",
    "        open_file = open('frank_Same_source_'+filename.split(\"_\")[1].split('.')[0]+'_and_baseline_'+filename.split('baseline')[-1].split('.')[0]+'_cross_validation_RFC.txt','w')\n",
    "\n",
    "        importances = HHrfc.feature_importances_\n",
    "        std = np.std([tree.feature_importances_ for tree in HHrfc.estimators_],\n",
    "                     axis=0)\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "\n",
    "        feature_space= []\n",
    "        # Print the feature ranking\n",
    "        open_file.write(\"Feature ranking: HH\")\n",
    "\n",
    "        for f in range(x_train0HH[names].shape[1]):\n",
    "            open_file.write(\"%d. feature %s (%f)\" % (f + 1, names[indices[f]], importances[indices[f]]))\n",
    "            feature_space.append(names[indices[f]])\n",
    "\n",
    "            \n",
    "        importances = HVrfc.feature_importances_\n",
    "        std = np.std([tree.feature_importances_ for tree in HVfc.estimators_],\n",
    "                     axis=0)\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "\n",
    "        feature_space= []\n",
    "        # Print the feature ranking\n",
    "        open_file.write(\"Feature ranking: HV\")\n",
    "\n",
    "        for f in range(x_train0HH[names].shape[1]):\n",
    "            open_file.write(\"%d. feature %s (%f)\" % (f + 1, names[indices[f]], importances[indices[f]]))\n",
    "            feature_space.append(names[indices[f]])\n",
    "        \n",
    "        importances = VVrfc.feature_importances_\n",
    "        std = np.std([tree.feature_importances_ for tree in VVrfc.estimators_],\n",
    "                     axis=0)\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "\n",
    "        feature_space= []\n",
    "        # Print the feature ranking\n",
    "        open_file.write(\"Feature ranking: VV\")\n",
    "\n",
    "        for f in range(x_train0HH[names].shape[1]):\n",
    "            open_file.write(\"%d. feature %s (%f)\" % (f + 1, names[indices[f]], importances[indices[f]]))\n",
    "            feature_space.append(names[indices[f]])\n",
    "        open_file.close()\n",
    "\n",
    "\n",
    "datasets = []\n",
    "files = []\n",
    "for filename in data_files:#[:15]:\n",
    "    data = pd.DataFrame.from_csv(filename)\n",
    "    if len(np.where(data[\"rfi\"].values == 1)[0])/float(len(data[\"rfi\"])) < 0.4:\n",
    "        for name in names:\n",
    "            data[name] = normalize(data[name],norm='l2')[0]\n",
    "        HH_X0 = data\n",
    "        files.append(filename)\n",
    "        del data\n",
    "        data = pd.DataFrame.from_csv(filename.replace('HH','VV'))\n",
    "        for name in names:\n",
    "            data[name] = normalize(data[name],norm='l2')[0]\n",
    "        VV_X0 = data\n",
    "        del data\n",
    "        data = pd.DataFrame.from_csv(filename.replace('HH','HV'))\n",
    "        for name in names:\n",
    "            data[name] = normalize(data[name],norm='l2')[0]\n",
    "        HV_X0 = data\n",
    "        del data\n",
    "        \n",
    "        \n",
    "        x_train0HH, x_test0HH, y_train0HH, y_test0HH = train_test_split(HH_X0[names], HH_X0['rfi'], test_size=0.30,random_state=0)\n",
    "\n",
    "        x_train0HV, x_test0HV, y_train0HV, y_test0HV = train_test_split(HV_X0[names], HV_X0['rfi'], test_size=0.30,random_state=0)\n",
    "\n",
    "        x_train0VV, x_test0VV, y_train0VV, y_test0VV = train_test_split(VV_X0[names], VV_X0['rfi'], test_size=0.30,random_state=0)\n",
    "\n",
    "        x_train0HH['rfi'] = y_train0HH\n",
    "        x_train0VV['rfi'] = y_train0VV\n",
    "        x_train0HV['rfi'] = y_train0HV\n",
    "        \n",
    "        HHcv = StratifiedKFold(x_train0HH, n_folds=15,shuffle=True, random_state=0)\n",
    "        VVcv = StratifiedKFold(x_train0VV, n_folds=15,shuffle=True, random_state=0)\n",
    "        HVcv = StratifiedKFold(x_train0HV, n_folds=15,shuffle=True, random_state=0)\n",
    "        rfc = KNeighborsClassifier(algorithm='auto')\n",
    "        grid = {\"n_neighbors\": np.arange(1,20)\n",
    "                ,'weights ': ['uniform','distance']\n",
    "                ,'p':np.arange(1,10)}\n",
    "\n",
    "        HHrfc = RandomizedSearchCV(rfc, grid, cv=HHcv,n_iter=20)\n",
    "        HHrfc.fit(x_train0HH[names],y_train0HH)\n",
    "        VVrfc = RandomizedSearchCV(rfc, grid, cv=VVcv,n_iter=20)\n",
    "        VVrfc.fit(x_train0VV[names],y_train0VV)\n",
    "        HVrfc = RandomizedSearchCV(rfc, grid, cv=HVcv,n_iter=20)\n",
    "        HVrfc.fit(x_train0HV[names],y_train0HV)\n",
    "        \n",
    "        \n",
    "        HHrfc = HHrfc.best_estimator_\n",
    "        HHrfc.fit(x_train0HH[names],y_train0HH)\n",
    "        HHy_pred_prob_rfc = HHrfc.predict_proba(x_test0HH)\n",
    "        HHy_pred_rfc = HHrfc.predict(x_test0HH)\n",
    "        \n",
    "        VVrfc = VVrfc.best_estimator_\n",
    "        VVrfc.fit(x_train0VV[names],y_train0VV)\n",
    "        VVy_pred_prob_rfc = VVrfc.predict_proba(x_test0VV)\n",
    "        VVy_pred_rfc = VVrfc.predict(x_test0VV)\n",
    "\n",
    "        HVrfc = HHrfc.best_estimator_\n",
    "        HVrfc.fit(x_train0HV[names],y_train0HV)\n",
    "        HVy_pred_prob_rfc = HVrfc.predict_proba(x_test0HV)\n",
    "        HVy_pred_rfc = HVrfc.predict(x_test0HV)\n",
    "        \n",
    "        def roc_plot(classifiers,subplot,model_names):\n",
    "    #c = ['r','g','b']\n",
    "            if subplot == True:\n",
    "                num = len(classifiers)\n",
    "                sns.plt.figure()\n",
    "                for i in range(num):\n",
    "                    sns.plt.subplot(1,num,i+1)\n",
    "                    clf = classifiers[i]\n",
    "                    y_roc_fpr, y_roc_tpr, y_roc_thresholds = roc_curve(y_test0, clf[:,1])\n",
    "                    sns.plt.plot(y_roc_fpr, y_roc_tpr,label=model_names[i]+' AUC = %0.2f'% auc(y_roc_fpr, y_roc_tpr))\n",
    "                    sns.plt.legend(loc='lower right',fontsize = 20 )\n",
    "                    sns.plt.plot([0,1],[0,1],'r--')\n",
    "                    sns.plt.xlim([-0.1,1.2])\n",
    "                    sns.plt.ylim([-0.1,1.2])\n",
    "                    sns.plt.ylabel('True Positive Rate',fontsize = 34 ,fontweight='bold')\n",
    "                    sns.plt.xlabel('False Positive Rate',fontsize = 34 ,fontweight='bold')\n",
    "                    sns.plt.xticks(size=18)\n",
    "                    sns.plt.yticks(size=18)\n",
    "            if subplot == False:\n",
    "                num = len(classifiers)\n",
    "                sns.plt.figure(figsize=(20,20))\n",
    "                for i in range(num):\n",
    "                    clf = classifiers[i]\n",
    "                    if 'VV' in model_names[i]:\n",
    "                        y_roc_fpr, y_roc_tpr, y_roc_thresholds = roc_curve(y_test0VV, clf[:,1])\n",
    "                    elif 'HV' in model_names[i]:\n",
    "                        y_roc_fpr, y_roc_tpr, y_roc_thresholds = roc_curve(y_test0HV, clf[:,1])\n",
    "                    else:\n",
    "                        y_roc_fpr, y_roc_tpr, y_roc_thresholds = roc_curve(y_test0HH, clf[:,1])\n",
    "                    sns.plt.plot(y_roc_fpr, y_roc_tpr,label=model_names[i]+' AUC = %0.2f'% auc(y_roc_fpr, y_roc_tpr))\n",
    "                    sns.plt.legend(loc='lower right',fontsize = 20 )\n",
    "                    sns.plt.plot([0,1],[0,1],'r--')\n",
    "                    sns.plt.xlim([-0.1,1.2])\n",
    "                    sns.plt.ylim([-0.1,1.2])\n",
    "                    sns.plt.ylabel('True Positive Rate',fontsize = 34 ,fontweight='bold')\n",
    "                    sns.plt.xlabel('False Positive Rate',fontsize = 34 ,fontweight='bold')\n",
    "                    sns.plt.xticks(size=18)\n",
    "                    sns.plt.yticks(size=18)\n",
    "            sns.plt.savefig('ROC_Same_source_'+filename.split(\"_\")[1].split('.')[0]+'_and_baseline_'+filename.split('baseline')[-1].split('.')[0]+'_cross_validation_KNN.eps', format='eps', dpi=600)\n",
    "            return\n",
    "        model_names =['HH','VV','HV']\n",
    "        roc_plot([HHy_pred_prob_rfc ,VVy_pred_prob_rfc,HVy_pred_prob_rfc],False,model_names)\n",
    "        \n",
    "        cnf_matrix = confusion_matrix(y_test0HH,HHy_pred_rfc)\n",
    "        sns.plt.figure(figsize=(20,20))\n",
    "        sns.plt.imshow(cnf_matrix, interpolation='nearest', cmap=sns.plt.cm.Blues)\n",
    "        classes = target_names \n",
    "        #sns.plt.title(title)\n",
    "        sns.plt.colorbar()\n",
    "        tick_marks = np.arange(len(classes))\n",
    "        sns.plt.xticks(tick_marks, classes, rotation=45)\n",
    "        sns.plt.yticks(tick_marks, classes)\n",
    "\n",
    "        #if normalize:\n",
    "        #    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            #print(\"Normalized confusion matrix\")\n",
    "        #else:\n",
    "        #    pass\n",
    "            #print('Confusion matrix, without normalization')\n",
    "\n",
    "        #print(cm)\n",
    "\n",
    "        thresh = cnf_matrix.max() / 2.\n",
    "        for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n",
    "            sns.plt.text(j, i, round(cnf_matrix[i, j],3),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cnf_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "        sns.plt.tight_layout()\n",
    "        sns.plt.grid(False)\n",
    "        sns.plt.ylabel('True label',fontsize = 34 ,fontweight='bold')\n",
    "        sns.plt.xlabel('Predicted label',fontsize = 34 ,fontweight='bold')\n",
    "        sns.plt.xticks(size=18)\n",
    "        sns.plt.yticks(size=18)\n",
    "        sns.plt.savefig('HH_Confusion_matrix_Same_source_'+filename.split(\"_\")[1].split('.')[0]+'_and_baseline_'+filename.split('baseline')[-1].split('.')[0]+'_cross_validation_KNN.eps', format='eps', dpi=600)\n",
    "        \n",
    "        open_file = open('HH_class_Same_source_'+filename.split(\"_\")[1].split('.')[0]+'_and_baseline_'+filename.split('baseline')[-1].split('.')[0]+'_cross_validation_KNN.txt','w')\n",
    "        \n",
    "        open_file.write('====================================================')\n",
    "        open_file.write('Classification Report for HH')\n",
    "        open_file.write('====================================================')\n",
    "        open_file.write(classification_report(y_test0HH,HHy_pred_rfc,target_names=['Not RFI','RFI']))\n",
    "        open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0HH,HHy_pred_rfc)*100))\n",
    "        open_file.close()\n",
    "        \n",
    "        cnf_matrix = confusion_matrix(y_test0HV,HVy_pred_rfc)\n",
    "        sns.plt.figure(figsize=(20,20))\n",
    "        sns.plt.imshow(cnf_matrix, interpolation='nearest', cmap=sns.plt.cm.Blues)\n",
    "        classes = target_names \n",
    "        #sns.plt.title(title)\n",
    "        sns.plt.colorbar()\n",
    "        tick_marks = np.arange(len(classes))\n",
    "        sns.plt.xticks(tick_marks, classes, rotation=45)\n",
    "        sns.plt.yticks(tick_marks, classes)\n",
    "\n",
    "        #if normalize:\n",
    "        #    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            #print(\"Normalized confusion matrix\")\n",
    "        #else:\n",
    "        #    pass\n",
    "            #print('Confusion matrix, without normalization')\n",
    "\n",
    "        #print(cm)\n",
    "\n",
    "        thresh = cnf_matrix.max() / 2.\n",
    "        for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n",
    "            sns.plt.text(j, i, round(cnf_matrix[i, j],3),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cnf_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "        sns.plt.tight_layout()\n",
    "        sns.plt.grid(False)\n",
    "        sns.plt.ylabel('True label',fontsize = 34 ,fontweight='bold')\n",
    "        sns.plt.xlabel('Predicted label',fontsize = 34 ,fontweight='bold')\n",
    "        sns.plt.xticks(size=18)\n",
    "        sns.plt.yticks(size=18)\n",
    "        sns.plt.savefig('HV_Confusion_matrix_Same_source_'+filename.split(\"_\")[1].split('.')[0]+'_and_baseline_'+filename.split('baseline')[-1].split('.')[0]+'_cross_validation_KNN.eps', format='eps', dpi=600)\n",
    "        \n",
    "        open_file = open('HV_class_Same_source_'+filename.split(\"_\")[1].split('.')[0]+'_and_baseline_'+filename.split('baseline')[-1].split('.')[0]+'_cross_validation_KNN.txt','w')\n",
    "        \n",
    "        open_file.write('====================================================')\n",
    "        open_file.write('Classification Report for HV')\n",
    "        open_file.write('====================================================')\n",
    "        open_file.write(classification_report(y_test0HV,HVy_pred_rfc,target_names=['Not RFI','RFI']))\n",
    "        open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0HV,HVy_pred_rfc)*100))\n",
    "        open_file.close()\n",
    "        \n",
    "        cnf_matrix = confusion_matrix(y_test0VV,VVy_pred_rfc)\n",
    "        sns.plt.figure(figsize=(20,20))\n",
    "        sns.plt.imshow(cnf_matrix, interpolation='nearest', cmap=sns.plt.cm.Blues)\n",
    "        classes = target_names \n",
    "        #sns.plt.title(title)\n",
    "        sns.plt.colorbar()\n",
    "        tick_marks = np.arange(len(classes))\n",
    "        sns.plt.xticks(tick_marks, classes, rotation=45)\n",
    "        sns.plt.yticks(tick_marks, classes)\n",
    "\n",
    "        #if normalize:\n",
    "        #    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            #print(\"Normalized confusion matrix\")\n",
    "        #else:\n",
    "        #    pass\n",
    "            #print('Confusion matrix, without normalization')\n",
    "\n",
    "        #print(cm)\n",
    "\n",
    "        thresh = cnf_matrix.max() / 2.\n",
    "        for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n",
    "            sns.plt.text(j, i, round(cnf_matrix[i, j],3),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cnf_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "        sns.plt.tight_layout()\n",
    "        sns.plt.grid(False)\n",
    "        sns.plt.ylabel('True label',fontsize = 34 ,fontweight='bold')\n",
    "        sns.plt.xlabel('Predicted label',fontsize = 34 ,fontweight='bold')\n",
    "        sns.plt.xticks(size=18)\n",
    "        sns.plt.yticks(size=18)\n",
    "        sns.plt.savefig('VV_Confusion_matrix_Same_source_'+filename.split(\"_\")[1].split('.')[0]+'_and_baseline_'+filename.split('baseline')[-1].split('.')[0]+'_cross_validation_KNN.eps', format='eps', dpi=600)\n",
    "        \n",
    "        open_file = open('VV_class_Same_source_'+filename.split(\"_\")[1].split('.')[0]+'_and_baseline_'+filename.split('baseline')[-1].split('.')[0]+'_cross_validation_KNN.txt','w')\n",
    "        \n",
    "        open_file.write('====================================================')\n",
    "        open_file.write('Classification Report for VV')\n",
    "        open_file.write('====================================================')\n",
    "        open_file.write(classification_report(y_test0VV,VVy_pred_rfc,target_names=['Not RFI','RFI']))\n",
    "        open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0VV,VVy_pred_rfc)*100))\n",
    "        open_file.close()\n",
    "        \n",
    "        #testVV = pd.DataFrame.from_csv('VV1333305511_pks1613-586.1822.ms_all_data_baseline0and1.csv')\n",
    "        open_file = open('poltest_Same_source_'+filename.split(\"_\")[1].split('.')[0]+'_and_baseline_'+filename.split('baseline')[-1].split('.')[0]+'_cross_validation_KNN.txt','w')\n",
    "\n",
    "        open_file.write(\"HH\")\n",
    "        y_pred_rfc = HHrfc.predict(x_test0HH)\n",
    "        open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0HH,y_pred_rfc)*100))\n",
    "\n",
    "        y_pred_rfc = HHrfc.predict(x_test0VV)\n",
    "        open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0VV,y_pred_rfc)*100))\n",
    "\n",
    "        y_pred_rfc = HHrfc.predict(x_test0HV)\n",
    "        open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0HV,y_pred_rfc)*100))\n",
    "\n",
    "\n",
    "        open_file.write(\"VV\")\n",
    "        y_pred_rfc = VVrfc.predict(x_test0HH)\n",
    "        open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0HH,y_pred_rfc)*100))\n",
    "\n",
    "        y_pred_rfc = VVrfc.predict(x_test0VV)\n",
    "        open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0VV,y_pred_rfc)*100))\n",
    "\n",
    "        y_pred_rfc = VVrfc.predict(x_test0HV)\n",
    "        open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0HV,y_pred_rfc)*100))\n",
    "\n",
    "        open_file.write(\"HV\")\n",
    "        y_pred_rfc = HVrfc.predict(x_test0HH)\n",
    "        open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0HH,y_pred_rfc)*100))\n",
    "\n",
    "        y_pred_rfc = HVrfc.predict(x_test0VV)\n",
    "        open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0VV,y_pred_rfc)*100))\n",
    "\n",
    "        y_pred_rfc = HVrfc.predict(x_test0HV)\n",
    "        open_file.write('\\n The model is %f accurate' %(accuracy_score(y_test0HV,y_pred_rfc)*100))\n",
    "        \n",
    "        open_file.close()\n",
    "        \n",
    "        pickle.dump(HHrfc,open('HH_Same_source_'+filename.split(\"_\")[1].split('.')[0]+'_and_baseline_'+filename.split('baseline')[-1].split('.')[0]+'_cross_validation_KNN.p','wb'))\n",
    "        pickle.dump(HVrfc,open('HV_Same_source_'+filename.split(\"_\")[1].split('.')[0]+'_and_baseline_'+filename.split('baseline')[-1].split('.')[0]+'_cross_validation_KNN.p','wb'))\n",
    "        pickle.dump(VVrfc,open('VV_Same_source_'+filename.split(\"_\")[1].split('.')[0]+'_and_baseline_'+filename.split('baseline')[-1].split('.')[0]+'_cross_validation_KNN.p','wb'))\n",
    "\n",
    "\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
